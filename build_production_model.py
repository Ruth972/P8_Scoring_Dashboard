import mlflow
import mlflow.pyfunc
import joblib
import shap
import pandas as pd
import numpy as np
import os

# ==============================================================================
# âš™ï¸ CONFIGURATION DU MODÃˆLE
# ==============================================================================

# 1. TON SEUIL OPTIMAL (Celui calculÃ© dans ton Notebook P7)
# D'aprÃ¨s tes tests prÃ©cÃ©dents, c'Ã©tait environ 0.067.
# âš ï¸ VÃ©rifie cette valeur dans ton notebook de modÃ©lisation !
OPTIMAL_THRESHOLD = 0.067 

# 2. Chemin vers ton fichier modÃ¨le actuel
CURRENT_MODEL_PATH = "./mlruns/9/models/m-0a84d69a2e314f0e82736c01fbcdd540/artifacts/model.pkl"

# ==============================================================================
# ðŸ§  DÃ‰FINITION DU WRAPPER (Pipeline + SHAP + Seuil Custom)
# ==============================================================================
class CreditScoringWrapper(mlflow.pyfunc.PythonModel):
    
    def load_context(self, context):
        """
        Chargement intelligent : On sÃ©pare le Pipeline en deux morceaux.
        1. Le Preprocessor (pour transformer les donnÃ©es avant SHAP)
        2. Le Classifieur (pour calculer SHAP)
        """
        print("Initialisation du Wrapper de Production...")
        
        # Chargement du Pipeline complet (ImbPipeline)
        self.pipeline = joblib.load(context.artifacts["model_file"])
        
        # --- EXTRACTION POUR SHAP ---
        # SHAP ne digÃ¨re pas les Pipelines entiers, il veut juste le modÃ¨le final.
        if hasattr(self.pipeline, 'steps'):
            # Le modÃ¨le est la derniÃ¨re Ã©tape (index -1)
            self.model_classifier = self.pipeline.steps[-1][1]
            # Le prÃ©processeur est tout ce qu'il y a avant (slicing [:-1])
            self.preprocessor = self.pipeline[:-1]
        else:
            # Cas oÃ¹ ce n'est pas un pipeline mais juste un modÃ¨le
            self.model_classifier = self.pipeline
            self.preprocessor = None
        
        print(f"ModÃ¨le extrait : {type(self.model_classifier)}")
        print("Initialisation de SHAP TreeExplainer...")
        
        # On initialise SHAP sur le classifieur uniquement
        self.explainer = shap.TreeExplainer(self.model_classifier)

    def predict(self, context, model_input):
        """
        PrÃ©diction avec seuil personnalisÃ© et explication SHAP
        """
        # 1. Calcul du Score (ProbabilitÃ©)
        # On utilise le pipeline complet, il gÃ¨re lui-mÃªme les transformations
        proba = self.pipeline.predict_proba(model_input)[:, 1]
        
        # 2. Calcul des SHAP Values
        # ATTENTION : Il faut donner Ã  SHAP des donnÃ©es transformÃ©es (mises Ã  l'Ã©chelle)
        if self.preprocessor:
            try:
                data_for_shap = self.preprocessor.transform(model_input)
            except Exception as e:
                print(f"Erreur transformation SHAP : {e}")
                data_for_shap = model_input # Fallback
        else:
            data_for_shap = model_input
            
        shap_values = self.explainer.shap_values(data_for_shap)
        
        # Gestion du format de retour SHAP (liste vs array)
        if isinstance(shap_values, list):
            vals = shap_values[1]
        else:
            vals = shap_values

        # 3. DÃ©cision mÃ©tier avec TON SEUIL
        # C'est ici qu'on utilise OPTIMAL_THRESHOLD au lieu de 0.5
        decision = ["REFUSÃ‰" if p > OPTIMAL_THRESHOLD else "ACCORDÃ‰" for p in proba]

        # 4. Retour formatÃ© pour l'API
        return {
            "score": proba.tolist(),
            "decision": decision,
            "threshold": OPTIMAL_THRESHOLD,
            "shap_values": vals.tolist()
        }

# ==============================================================================
# ðŸ“¦ CONSTRUCTION ET SAUVEGARDE
# ==============================================================================

if not os.path.exists(CURRENT_MODEL_PATH):
    raise FileNotFoundError(f"Fichier introuvable : {CURRENT_MODEL_PATH}")

artifacts = {
    "model_file": CURRENT_MODEL_PATH
}

print(f"ðŸ“¦ Emballage du modÃ¨le avec Seuil={OPTIMAL_THRESHOLD}...")

with mlflow.start_run(run_name="Production_Scoring_Final") as run:
    
    mlflow.pyfunc.log_model(
        artifact_path="scoring_model_final",
        python_model=CreditScoringWrapper(),
        artifacts=artifacts,
        # On force imbalanced-learn et scikit-learn compatible
        pip_requirements=["joblib", "scikit-learn", "shap", "pandas", "numpy", "imbalanced-learn"]
    )

print("\n" + "="*60)
print(f"âœ… MODÃˆLE DE PRODUCTION PRÃŠT !")
print(f"ðŸ‘‰ ID du Run : {run.info.run_id}")
print(f"ðŸ‘‰ Chemin : ./mlruns/0/{run.info.run_id}/artifacts/scoring_model_final")
print("="*60)